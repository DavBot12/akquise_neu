from playwright.sync_api import sync_playwright
from datetime import datetime
import json
import re
import time

BASE_URL = "https://www.willhaben.at/iad/immobilien/eigentumswohnung/eigentumswohnung-angebote"

def scrape_detail(page, url):
    page.goto(url, timeout=60000)
    page.wait_for_timeout(2500)  # JS lÃ¤dt
    html = page.content()
    text = page.inner_text('body')

    if "Anbieter: Privat" not in text:
        print(f"ğŸš« Gewerblich: {url}")
        return None

    # Titel
    try:
        title = page.locator("h1").first.inner_text().strip()
    except:
        title = "N/A"

    # Preis
    try:
        price_text = page.locator("span[class*='price']").first.inner_text()
        price = re.search(r"\d[\d\.\s]*", price_text).group().replace(".", "").replace(" ", "")
    except:
        price = "N/A"

    # WohnflÃ¤che (mÂ²)
    try:
        flaeche_block = re.findall(r"(\d{2,4})\s?mÂ²", text)
        qm = flaeche_block[0] if flaeche_block else "N/A"
    except:
        qm = "N/A"

    return {
        "title": title,
        "price_eur": price,
        "qm": qm,
        "url": url,
        "scraped_at": datetime.now().isoformat()
    }

def main():
    results = []

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        for page_num in range(1, 4):  # z.â€¯B. nur 3 Seiten zum Testen
            print(f"ğŸ” Suche Seite {page_num}")
            page.goto(f"{BASE_URL}?page={page_num}")
            page.wait_for_timeout(3000)

            links = page.locator("a[href*='/iad/immobilien/d/']").all()
            detail_urls = list(set([l.get_attribute("href").split("?")[0] for l in links if l.get_attribute("href")]))

            for rel_url in detail_urls:
                full_url = "https://www.willhaben.at" + rel_url
                print(f"ğŸ‘‰ PrÃ¼fe: {full_url}")
                data = scrape_detail(page, full_url)
                if data:
                    results.append(data)
                    print(f"âœ… Gefunden: {data['title']}")

        browser.close()

    # Speichern als JSON
    with open("willhaben_privat.json", "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"ğŸ“ Gespeichert: {len(results)} Inserate â†’ willhaben_privat.json")

if __name__ == "__main__":
    main()
